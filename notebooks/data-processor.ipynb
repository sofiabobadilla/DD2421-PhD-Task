{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessor\n",
    "\n",
    "Initial experiment setup\n",
    "\n",
    "- Initial idea: Classifier to identify vulnerable lines of code. \n",
    "- Dataset : smartbugs curated- vulnerable lines of code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the map of contracts and respective line of code\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "dataset= \"smartbugs-curated\"\n",
    "\n",
    "path='../dataset/'+dataset\n",
    "if dataset == 'smartbugs-curated' :\n",
    "    vulnerability_localization= json.load(open(path+'/vulnerabilities.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## now prepare the dataset, for each contract, get the line of code that is vulnerable\n",
    "base_path = f'../dataset/{dataset}'\n",
    "# Function to extract vulnerable lines\n",
    "def extract_vulnerable_lines(contract_data):\n",
    "    vulnerable_lines_data = []\n",
    "    vulnerable_lines = []\n",
    "    \n",
    "    for contract in contract_data:\n",
    "        contract_name = contract['name']\n",
    "        relative_path = contract['path']\n",
    "        full_path = os.path.join(base_path, relative_path)\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(full_path):\n",
    "            print(f\"Warning: File not found - {full_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Read the file content\n",
    "        try:\n",
    "            with open(full_path, 'r', encoding='utf-8') as file:\n",
    "                file_lines = file.readlines()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {full_path}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        # Process vulnerabilities\n",
    "        for vulnerability in contract['vulnerabilities']:\n",
    "            category = vulnerability['category']\n",
    "            \n",
    "            for line_number in vulnerability['lines']:\n",
    "                # Adjust for 0-based indexing\n",
    "                adjusted_line_number = line_number - 1\n",
    "                \n",
    "                # Extract the actual code (if line number is valid)\n",
    "                code_line = \"\"\n",
    "                if 0 <= adjusted_line_number < len(file_lines):\n",
    "                    code_line = file_lines[adjusted_line_number].strip()\n",
    "                else:\n",
    "                    print(f\"Warning: Line {line_number} out of range in {full_path}\")\n",
    "                \n",
    "                vulnerable_lines_data.append({\n",
    "                    'contract_name': contract_name,\n",
    "                    'contract_path': relative_path,\n",
    "                    'full_path': full_path,\n",
    "                    'pragma_version': contract['pragma'],\n",
    "                    'source': contract['source'],\n",
    "                    'line_number': line_number,\n",
    "                    'vulnerability_category': category,\n",
    "                    'code': code_line\n",
    "                })\n",
    "                vulnerable_lines.append(code_line)\n",
    "    \n",
    "    return vulnerable_lines_data, vulnerable_lines\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n",
      "[{'contract_name': 'FibonacciBalance.sol', 'contract_path': 'dataset/access_control/FibonacciBalance.sol', 'full_path': '../dataset/smartbugs-curated/dataset/access_control/FibonacciBalance.sol', 'pragma_version': '0.4.22', 'source': 'https://github.com/sigp/solidity-security-blog', 'line_number': 31, 'vulnerability_category': 'access_control', 'code': 'require(fibonacciLibrary.delegatecall(fibSig, withdrawalCounter));'}, {'contract_name': 'FibonacciBalance.sol', 'contract_path': 'dataset/access_control/FibonacciBalance.sol', 'full_path': '../dataset/smartbugs-curated/dataset/access_control/FibonacciBalance.sol', 'pragma_version': '0.4.22', 'source': 'https://github.com/sigp/solidity-security-blog', 'line_number': 38, 'vulnerability_category': 'access_control', 'code': 'require(fibonacciLibrary.delegatecall(msg.data));'}, {'contract_name': 'arbitrary_location_write_simple.sol', 'contract_path': 'dataset/access_control/arbitrary_location_write_simple.sol', 'full_path': '../dataset/smartbugs-curated/dataset/access_control/arbitrary_location_write_simple.sol', 'pragma_version': '0.4.25', 'source': 'https://smartcontractsecurity.github.io/SWC-registry/docs/SWC-124#arbitrary-location-write-simplesol', 'line_number': 27, 'vulnerability_category': 'access_control', 'code': 'require(0 <= bonusCodes.length); // this condition is always true since array lengths are unsigned'}]\n",
      "['require(fibonacciLibrary.delegatecall(fibSig, withdrawalCounter));', 'require(fibonacciLibrary.delegatecall(msg.data));', 'require(0 <= bonusCodes.length); // this condition is always true since array lengths are unsigned']\n"
     ]
    }
   ],
   "source": [
    "vulnerable_lines_data,vulnerable_lines = extract_vulnerable_lines(vulnerability_localization)\n",
    "print(len(vulnerable_lines_data))\n",
    "print(vulnerable_lines_data[0:3])\n",
    "print(vulnerable_lines[0:3])\n",
    "\n",
    "\n",
    "## storage data\n",
    "with open(f'../dataset/{dataset}_vulnerable_lines.json', 'w') as file:\n",
    "    json.dump(vulnerable_lines_data, file, indent=4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get an equal amount of non-vulnerable lines\n",
    "# current vulnerable lines 222\n",
    "\n",
    "import random\n",
    "import re\n",
    "\n",
    "def get_pragma_version(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        file_lines = file.readlines()\n",
    "    #regex to get the pragma version\n",
    "    while file_lines[0].strip().startswith(\"pragma\") == False:\n",
    "        file_lines.pop(0)\n",
    "    \n",
    "    pragma_line= file_lines[0].strip()\n",
    "\n",
    "    # now only get the pragma version\n",
    "    match = re.search(r'pragma solidity \\^?([\\d\\.]+);', pragma_line)\n",
    "\n",
    "    if match:\n",
    "        version = match.group(1)\n",
    "        return version\n",
    "    return None\n",
    "\n",
    "def extract_non_vulnerable_lines(vulnerable_lines_data, num_samples):\n",
    "    non_vulnerable_lines = []\n",
    "    \n",
    "    # Load all contract files\n",
    "    contract_files = []\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.sol'):\n",
    "                contract_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Extract non-vulnerable lines\n",
    "    while len(non_vulnerable_lines) < num_samples:\n",
    "        # Randomly select a contract file\n",
    "        contract_file = random.choice(contract_files)\n",
    "        \n",
    "        # Read the file content\n",
    "        try:\n",
    "            with open(contract_file, 'r', encoding='utf-8') as file:\n",
    "                file_lines = file.readlines()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {contract_file}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Randomly select a line\n",
    "        line_number = random.randint(0, len(file_lines) - 1)\n",
    "        code_line = file_lines[line_number].strip()\n",
    "        pragma= get_pragma_version(contract_file)\n",
    "        \n",
    "        # Check if line is a comment or blank\n",
    "        if re.match(r'^\\s*(//|$)', code_line):\n",
    "            continue\n",
    "        \n",
    "        # Check if the exact line from the contract is already in vulnerable lines\n",
    "        \n",
    "        if any((line['code'] == code_line and line[\"full_path\"]==contract_file and line[\"line_number\"]==line_number) for line in vulnerable_lines_data):\n",
    "            print(\"duplicate\")\n",
    "            continue\n",
    "        \n",
    "        # Add to non-vulnerable lines\n",
    "        non_vulnerable_lines.append({\n",
    "            'contract_path': os.path.relpath(contract_file, base_path),\n",
    "            'full_path': contract_file,\n",
    "            'line_number': line_number + 1,\n",
    "            'code': code_line,\n",
    "            'pragma_version':pragma\n",
    "        })\n",
    "    \n",
    "    return non_vulnerable_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n",
      "[{'contract_path': 'dataset/arithmetic/overflow_single_tx.sol', 'full_path': '../dataset/smartbugs-curated/dataset/arithmetic/overflow_single_tx.sol', 'line_number': 2, 'code': '* @source: https://github.com/ConsenSys/evm-analyzer-benchmark-suite', 'pragma_version': '0.4.23'}, {'contract_path': 'dataset/reentrancy/0x4320e6f8c05b27ab4707cd1f6d5ce6f3e4b3a5a1.sol', 'full_path': '../dataset/smartbugs-curated/dataset/reentrancy/0x4320e6f8c05b27ab4707cd1f6d5ce6f3e4b3a5a1.sol', 'line_number': 32, 'code': '}', 'pragma_version': '0.4.19'}, {'contract_path': 'dataset/reentrancy/etherstore.sol', 'full_path': '../dataset/smartbugs-curated/dataset/reentrancy/etherstore.sol', 'line_number': 5, 'code': '*/', 'pragma_version': '0.4.10'}]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "non_vulnerable_lines= extract_non_vulnerable_lines(vulnerable_lines_data, len(vulnerable_lines_data))\n",
    "print(len(non_vulnerable_lines))\n",
    "print(non_vulnerable_lines[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## storage data\n",
    "final_data= vulnerable_lines_data + non_vulnerable_lines\n",
    "with open(f'../dataset/{dataset}_final_data.json', 'w') as file:\n",
    "    json.dump(final_data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding\n",
    "\n",
    "To encode the data points from both datasets, I considered the following criteria:\n",
    "\n",
    "- **Code Encoding**  \n",
    "  1. `code_enc:` Encodes each unique Solidity code snippet using `LabelEncoder`, assigning a unique integer to each distinct snippet.\n",
    "\n",
    "- **Token Count**  \n",
    "  2. `tokens:` Tokenizes Solidity code by removing comments and splitting on non-alphanumeric characters. The total count of tokens is stored as a numerical feature.\n",
    "\n",
    "- **Presence of External Calls**  \n",
    "  3. `has_external_call:` Checks if the Solidity code contains low-level function calls like `call`, `delegatecall`, `staticcall`, `send`, or `transfer`. Stores this as a binary feature (1 if present, 0 otherwise).\n",
    "\n",
    "- **Presence of Require or Assert**  \n",
    "  4. `has_require_assert:` Checks if the Solidity code contains the `require` or `assert` statements. Stores this as a binary feature (1 if present, 0 otherwise).\n",
    "\n",
    "- **Pragma Version Encoding**  \n",
    "  5. `pragma_major:` Extracts and encodes the major version from the Solidity `pragma` statement as an integer.  \n",
    "  6. `pragma_minor:` Extracts and encodes the minor version from the Solidity `pragma` statement as an integer.  \n",
    "  7. `pragma_patch:` Extracts and encodes the patch version from the Solidity `pragma` statement as an integer.\n",
    "\n",
    "- **Line Number Normalization**  \n",
    "  8. `line_number:` Normalizes the line number using `MinMaxScaler` to scale values between 0 and 1.\n",
    "\n",
    "- **Label Encoding**  \n",
    "  9. `label:` Converts the vulnerability label into an integer (0 or 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# Helper function to tokenize Solidity code\n",
    "def tokenize_code(code):\n",
    "    # Remove comments\n",
    "    code = re.sub(r\"//.*|/\\*[\\s\\S]*?\\*/\", \"\", code)\n",
    "    # Tokenize by splitting on non-alphanumeric characters\n",
    "    tokens = re.findall(r\"\\w+\", code)\n",
    "    return tokens\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(data):\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    #Code Encoding\n",
    "    code_enc = LabelEncoder()\n",
    "    df[\"code_enc\"] = code_enc.fit_transform(df[\"code\"])\n",
    "\n",
    "    # Tokenization - only keep the number of tokens\n",
    "    df[\"tokens\"] = df[\"code\"].apply(tokenize_code)\n",
    "    df['tokens']= df['tokens'].apply(len)\n",
    "    \n",
    "    # Presence of external calls\n",
    "    external_calls = [\"call\", \"delegatecall\", \"staticcall\", \"send\", \"transfer\"]\n",
    "    df[\"has_external_call\"] = df[\"code\"].apply(lambda x: any(call in x for call in external_calls)).astype(int)\n",
    "    \n",
    "    # Presence of `require` or `assert`\n",
    "    df[\"has_require_assert\"] = df[\"code\"].apply(lambda x: \"require\" in x or \"assert\" in x).astype(int)\n",
    "\n",
    "    # Encoding categorical variables\n",
    "    df[\"pragma_version\"] = df[\"pragma_version\"].apply(lambda x: tuple(map(int, x.lstrip(\"^\").split(\".\"))) if x else (0, 0, 0))\n",
    "    df[[\"pragma_major\", \"pragma_minor\", \"pragma_patch\"]] = pd.DataFrame(df[\"pragma_version\"].tolist(), index=df.index)\n",
    "\n",
    "\n",
    "    # Normalize `line_number`\n",
    "    scaler = MinMaxScaler()\n",
    "    df[\"line_number\"] = scaler.fit_transform(df[[\"line_number\"]])\n",
    "\n",
    "    if \"label\" in df.columns:\n",
    "        df[\"label\"] = df[\"label\"].astype(int)\n",
    "    else:\n",
    "        # vulnerable if vulnerability category is not empty\n",
    "        df[\"label\"]= df[\"vulnerability_category\"].apply(lambda x: False if pd.isna(x) else True)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "\n",
    "    return df.drop(columns=[\"pragma_version\", \"code\", \"contract_path\", \"full_path\", \"source\", \"vulnerability_category\",\"contract_name\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_number</th>\n",
       "      <th>code_enc</th>\n",
       "      <th>tokens</th>\n",
       "      <th>has_external_call</th>\n",
       "      <th>has_require_assert</th>\n",
       "      <th>pragma_major</th>\n",
       "      <th>pragma_minor</th>\n",
       "      <th>pragma_patch</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012165</td>\n",
       "      <td>218</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015004</td>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010543</td>\n",
       "      <td>209</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007705</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006894</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.070154</td>\n",
       "      <td>280</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.007705</td>\n",
       "      <td>278</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.010543</td>\n",
       "      <td>181</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.005272</td>\n",
       "      <td>177</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.006488</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line_number  code_enc  tokens  has_external_call  has_require_assert  \\\n",
       "0       0.012165       218       5                  1                   1   \n",
       "1       0.015004       219       5                  1                   1   \n",
       "2       0.010543       209       4                  0                   1   \n",
       "3       0.007705       112       2                  0                   0   \n",
       "4       0.006894       132       2                  0                   0   \n",
       "..           ...       ...     ...                ...                 ...   \n",
       "217     0.070154       280       3                  1                   0   \n",
       "218     0.007705       278       3                  1                   0   \n",
       "219     0.010543       181       5                  1                   0   \n",
       "220     0.005272       177       4                  1                   0   \n",
       "221     0.006488        73       2                  1                   0   \n",
       "\n",
       "     pragma_major  pragma_minor  pragma_patch  label  \n",
       "0               0             4            22   True  \n",
       "1               0             4            22   True  \n",
       "2               0             4            25   True  \n",
       "3               0             4            24   True  \n",
       "4               0             4            24   True  \n",
       "..            ...           ...           ...    ...  \n",
       "217             0             4             0   True  \n",
       "218             0             4            18   True  \n",
       "219             0             4            18   True  \n",
       "220             0             4             0   True  \n",
       "221             0             4            25   True  \n",
       "\n",
       "[222 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = extract_features(final_data)\n",
    "encoded_data[encoded_data['label']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.to_csv(f'../dataset/{dataset}_encoded_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 355 samples\n",
      "Test data: 89 samples\n",
      "Train data: label\n",
      "True     178\n",
      "False    177\n",
      "Name: count, dtype: int64\n",
      "Test data: label\n",
      "False    45\n",
      "True     44\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now random split for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(encoded_data, test_size=0.2, random_state=42, stratify=encoded_data[\"label\"])\n",
    "train_data.to_csv(f'../dataset/{dataset}_train_data.csv', index=True, index_label=\"index\")\n",
    "test_data.to_csv(f'../dataset/{dataset}_test_data.csv', index=True, index_label=\"index\")\n",
    "\n",
    "\n",
    "print(f\"Train data: {len(train_data)} samples\")\n",
    "print(f\"Test data: {len(test_data)} samples\")\n",
    "print(f\"Train data: {train_data['label'].value_counts()}\")\n",
    "print(f\"Test data: {test_data['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Experiment Data\n",
    "Using the refinement of the smartbugs-curated dataset , sb-heist that evaluates the exploitability of each contract I'll train the model with this only True Positive dataset and compare the performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the map of contracts and respective line of code\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "dataset= \"sb-heists\"\n",
    "\n",
    "path='../dataset/'+dataset\n",
    "\n",
    "\n",
    "if dataset == 'sb-heists' :\n",
    "    exploitable_contracts= pd.read_csv(path+'/smartbugs-curated/0.4.x/contracts_w_exploits.csv', sep='/', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vulnerable_exploitable(exploit_list, vulnerable_lines_data):\n",
    "    exploit_list=exploit_list.values.tolist()\n",
    "    vulnerable_exploitable_label = []\n",
    "    for line in vulnerable_lines_data:\n",
    "        if any((line['vulnerability_category'] == vul and line[\"contract_name\"]==contract ) for vul, contract in exploit_list):\n",
    "            \n",
    "            line['label']= True\n",
    "            vulnerable_exploitable_label.append(line)\n",
    "        else:\n",
    "            line['label']= False\n",
    "            vulnerable_exploitable_label.append(line)\n",
    "    return vulnerable_exploitable_label\n",
    "\n",
    "vulnerable_exploitable_label= get_vulnerable_exploitable(exploitable_contracts, vulnerable_lines_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storage data\n",
    "with open(f'../dataset/{dataset}_vulnerable_exploitable_label.json', 'w') as file:\n",
    "    json.dump(vulnerable_exploitable_label, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now time to encode the data\n",
    "\n",
    "encoded_data = extract_features(vulnerable_exploitable_label)\n",
    "encoded_data.to_csv(f'../dataset/{dataset}_encoded_data.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_number</th>\n",
       "      <th>label</th>\n",
       "      <th>code_enc</th>\n",
       "      <th>tokens</th>\n",
       "      <th>has_external_call</th>\n",
       "      <th>has_require_assert</th>\n",
       "      <th>pragma_major</th>\n",
       "      <th>pragma_minor</th>\n",
       "      <th>pragma_patch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007739</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010591</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006110</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003259</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002444</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.065988</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.003259</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.006110</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.000815</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.002037</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line_number  label  code_enc  tokens  has_external_call  \\\n",
       "0       0.007739      1       115       5                  1   \n",
       "1       0.010591      1       116       5                  1   \n",
       "2       0.006110      1       109       4                  0   \n",
       "3       0.003259      1        59       2                  0   \n",
       "4       0.002444      1        67       2                  0   \n",
       "..           ...    ...       ...     ...                ...   \n",
       "217     0.065988      0       158       3                  1   \n",
       "218     0.003259      0       156       3                  1   \n",
       "219     0.006110      0        94       5                  1   \n",
       "220     0.000815      0        90       4                  1   \n",
       "221     0.002037      0        37       2                  1   \n",
       "\n",
       "     has_require_assert  pragma_major  pragma_minor  pragma_patch  \n",
       "0                     1             0             4            22  \n",
       "1                     1             0             4            22  \n",
       "2                     1             0             4            25  \n",
       "3                     0             0             4            24  \n",
       "4                     0             0             4            24  \n",
       "..                  ...           ...           ...           ...  \n",
       "217                   0             0             4             0  \n",
       "218                   0             0             4            18  \n",
       "219                   0             0             4            18  \n",
       "220                   0             0             4             0  \n",
       "221                   0             0             4            25  \n",
       "\n",
       "[222 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 177 samples\n",
      "Test data: 45 samples\n",
      "Train data: label\n",
      "1    106\n",
      "0     71\n",
      "Name: count, dtype: int64\n",
      "Test data: label\n",
      "1    27\n",
      "0    18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now random split for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(encoded_data, test_size=0.2, random_state=42, stratify=encoded_data[\"label\"])\n",
    "train_data.to_csv(f'../dataset/{dataset}_train_data.csv', index=True, index_label=\"index\")\n",
    "test_data.to_csv(f'../dataset/{dataset}_test_data.csv', index=True, index_label=\"index\")\n",
    "\n",
    "print(f\"Train data: {len(train_data)} samples\")\n",
    "print(f\"Test data: {len(test_data)} samples\")\n",
    "print(f\"Train data: {train_data['label'].value_counts()}\")\n",
    "print(f\"Test data: {test_data['label'].value_counts()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
